{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, f1_score, accuracy_score\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_variable = 'dbp' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../intermediate_data/scalogram_resnet_representation.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representation</th>\n",
       "      <th>patientid</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0031806, 1.2474066, 0.04806124, 0.35932362,...</td>\n",
       "      <td>20</td>\n",
       "      <td>178</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.520468, 1.3503281, 0.010736622, 0.15120158,...</td>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.5581223, 0.84562373, 0.0, 0.33805272, 0.169...</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.709408, 0.99573827, 0.03802151, 0.28552535,...</td>\n",
       "      <td>12</td>\n",
       "      <td>160</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.0288619, 1.0717208, 0.005405174, 0.31130534...</td>\n",
       "      <td>16</td>\n",
       "      <td>116</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      representation patientid  sbp dbp\n",
       "0  [1.0031806, 1.2474066, 0.04806124, 0.35932362,...        20  178  89\n",
       "1  [0.520468, 1.3503281, 0.010736622, 0.15120158,...        22  112  58\n",
       "2  [0.5581223, 0.84562373, 0.0, 0.33805272, 0.169...         2  143  69\n",
       "3  [0.709408, 0.99573827, 0.03802151, 0.28552535,...        12  160  78\n",
       "4  [1.0288619, 1.0717208, 0.005405174, 0.31130534...        16  116  70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['patientid'] = pd.to_numeric(df['patientid'])\n",
    "df['sbp'] = pd.to_numeric(df['sbp'])\n",
    "df['dbp'] = pd.to_numeric(df['dbp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.loc[(df['sbp'] == 0)|(df['dbp'] == 0)].index, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=512, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.1), activation='relu'))\n",
    "    model.add(Dense(20, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.1), activation='relu'))\n",
    "    #model.add(Dense(5, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.1), activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fold1\n",
      "running fold2\n",
      "running fold3\n",
      "running fold4\n",
      "running fold5\n",
      "running fold6\n",
      "running fold7\n",
      "running fold8\n",
      "running fold9\n",
      "running fold10\n",
      "running fold11\n",
      "running fold12\n",
      "running fold13\n",
      "average RMSE for the LR for dbp is 8.602114749317613 sd 2.2489694844680717\n",
      "average R2 for the LR for dbp is -1.1324873259808346 sd 1.1999999348000359\n",
      "average MAPE for the LR for dbp is 10.228215249214834 sd 3.7694908567674967\n",
      "average RMSE for the GBM for dbp is 8.693514336249187 sd 2.4312386222119344\n",
      "average R2 for the GBM for dbp is -1.230051481655818 sd 1.5057023367957585\n",
      "average MAPE for the GBM for dbp is 10.76127893723761 sd 3.6896581767413386\n",
      "average RMSE for the Dummy Predictor for dbp is 8.526479600790639 sd 2.558311151559337\n",
      "average R2 for the Dummy Predictor for dbp is -1.1515115217440466 sd 1.544290237263158\n",
      "average MAPE for the Dummy Predictor for dbp is 10.65367172913035 sd 3.815336180522183\n"
     ]
    }
   ],
   "source": [
    "patient_ids = np.unique(df['patientid'])\n",
    "\n",
    "estimator_base = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator_base, 40, step=1)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "estimators_lr = []\n",
    "#estimators_lr.append(('standardize', StandardScaler()))\n",
    "estimators_lr.append(('selector', selector))\n",
    "estimators_lr.append(('lr',  ElasticNet(alpha=0.1, l1_ratio=0.5, random_state = 42)))\n",
    "pipeline_lr = Pipeline(estimators_lr)\n",
    "\n",
    "estimators_gbm = []\n",
    "#estimators_gbm.append(('standardize', StandardScaler()))\n",
    "estimators_gbm.append(('selector', selector))\n",
    "estimators_gbm.append(('gbm',  GradientBoostingRegressor(learning_rate=0.01, n_estimators=50, random_state = 42)))\n",
    "pipeline_gbm = Pipeline(estimators_gbm)\n",
    "\n",
    "dummy_mean = DummyRegressor(strategy='mean')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RMSE_NN = []\n",
    "R2_NN = []\n",
    "MAPE_NN = []\n",
    "\n",
    "RMSE_LR = []\n",
    "R2_LR = []\n",
    "MAPE_LR = []\n",
    "\n",
    "RMSE_GBM = []\n",
    "R2_GBM = []\n",
    "MAPE_GBM = []\n",
    "\n",
    "RMSE_Dummy = []\n",
    "R2_Dummy = []\n",
    "MAPE_Dummy = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while len(patient_ids) > 1:\n",
    "    \n",
    "    i= i + 1\n",
    "    random.seed(42)\n",
    "    patient_test_ids = random.choices(patient_ids, k = 2)\n",
    "    patient_ids = [e for e in patient_ids if e not in patient_test_ids]\n",
    "    df_test = df.loc[df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    df_train = df[~df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    print(\"running fold\" + str(i))\n",
    "    \n",
    "    cols_dropped = ['patientid']\n",
    "\n",
    "    if predicted_variable == 'sbp':\n",
    "        cols_dropped.append('dbp')\n",
    "    elif predicted_variable == 'dbp':\n",
    "        cols_dropped.append('sbp')\n",
    "    df_train = df_train.drop(columns = cols_dropped)\n",
    "    df_test = df_test.drop(columns = cols_dropped)\n",
    "    \n",
    "    ##nn\n",
    "    #pipeline.fit(X = np.stack(df_train[\"representation\"]), y = df_train[predicted_variable].values)\n",
    "    #predicted_labels = pipeline.predict(np.stack(df_test[\"representation\"]))\n",
    "    \n",
    "    #RMSE_NN.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "    #R2_NN.append(r2_score(df_test[predicted_variable], predicted_labels))\n",
    "    #MAPE_NN.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    ##lr\n",
    "    pipeline_lr.fit(X = np.stack(df_train[\"representation\"]), y = df_train[predicted_variable].values)\n",
    "    predicted_labels = pipeline_lr.predict(np.stack(df_test[\"representation\"]))\n",
    "    \n",
    "    RMSE_LR.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "    R2_LR.append(r2_score(df_test[predicted_variable], predicted_labels))\n",
    "    MAPE_LR.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    #gbm \n",
    "    \n",
    "    pipeline_gbm.fit(X = np.stack(df_train[\"representation\"]), y = df_train[predicted_variable].values)\n",
    "    predicted_labels = pipeline_gbm.predict(np.stack(df_test[\"representation\"]))\n",
    "    \n",
    "    RMSE_GBM.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "    R2_GBM.append(r2_score(df_test[predicted_variable], predicted_labels))\n",
    "    MAPE_GBM.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    \n",
    "    ##dummy: predicting mean\n",
    "    \n",
    "    dummy_mean.fit(X = np.stack(df_train[\"representation\"]), y = df_train[predicted_variable].values)\n",
    "    predicted_labels = dummy_mean.predict(np.stack(df_test[\"representation\"]))\n",
    "    \n",
    "    RMSE_Dummy.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "    R2_Dummy.append(r2_score(df_test[predicted_variable], predicted_labels))\n",
    "    MAPE_Dummy.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate model with standardized dataset\n",
    "    \n",
    "#print(\"average RMSE for the NN for \" + predicted_variable + \" is \" + str(np.mean(np.array(RMSE_NN)))+ \" sd \" + str(np.std(np.array(RMSE_NN)))) \n",
    "#print(\"average R2 for the NN for \" + predicted_variable + \" is \" + str(np.mean(np.array(R2_NN)))+ \" sd \" + str(np.std(np.array(R2_NN))))\n",
    "#print(\"average MAPE for the NN for \" + predicted_variable + \" is \" + str(np.mean(np.array(MAPE_NN)))+ \" sd \" + str(np.std(np.array(MAPE_NN))))\n",
    "\n",
    "print(\"average RMSE for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(RMSE_LR)))+ \" sd \" + str(np.std(np.array(RMSE_LR)))) \n",
    "print(\"average R2 for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(R2_LR)))+ \" sd \" + str(np.std(np.array(R2_LR))))\n",
    "print(\"average MAPE for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(MAPE_LR)))+ \" sd \" + str(np.std(np.array(MAPE_LR))))\n",
    "\n",
    "print(\"average RMSE for the GBM for \" + predicted_variable + \" is \" + str(np.mean(np.array(RMSE_GBM)))+ \" sd \" + str(np.std(np.array(RMSE_GBM)))) \n",
    "print(\"average R2 for the GBM for \" + predicted_variable + \" is \" + str(np.mean(np.array(R2_GBM)))+ \" sd \" + str(np.std(np.array(R2_GBM))))\n",
    "print(\"average MAPE for the GBM for \" + predicted_variable + \" is \" + str(np.mean(np.array(MAPE_GBM)))+ \" sd \" + str(np.std(np.array(MAPE_GBM))))\n",
    "\n",
    "print(\"average RMSE for the Dummy Predictor for \" + predicted_variable + \" is \" + str(np.mean(np.array(RMSE_Dummy)))+ \" sd \" + str(np.std(np.array(RMSE_Dummy)))) \n",
    "print(\"average R2 for the Dummy Predictor for \" + predicted_variable + \" is \" + str(np.mean(np.array(R2_Dummy)))+ \" sd \" + str(np.std(np.array(R2_Dummy))))\n",
    "print(\"average MAPE for the Dummy Predictor for \" + predicted_variable + \" is \" + str(np.mean(np.array(MAPE_Dummy)))+ \" sd \" + str(np.std(np.array(MAPE_Dummy))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BP_Category'] = 'normal'\n",
    "#df.loc[(df['sbp'] > 120) & (df['sbp'] < 130) & (df['dbp'] < 80), 'BP_Category'] = 'elivated'\n",
    "df.loc[(df['sbp'] > 130) | (df['dbp'] > 80), 'BP_Category'] = 'hypertension'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hypertension    95\n",
       "normal          53\n",
       "Name: BP_Category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BP_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fold1\n",
      "hypertension    84\n",
      "normal          47\n",
      "Name: BP_Category, dtype: int64\n",
      "normal          12\n",
      "hypertension     5\n",
      "dtype: int64\n",
      "running fold2\n",
      "hypertension    87\n",
      "normal          45\n",
      "Name: BP_Category, dtype: int64\n",
      "normal          9\n",
      "hypertension    7\n",
      "dtype: int64\n",
      "running fold3\n",
      "hypertension    82\n",
      "normal          49\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    10\n",
      "normal           7\n",
      "dtype: int64\n",
      "running fold4\n",
      "hypertension    81\n",
      "normal          49\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    12\n",
      "normal           6\n",
      "dtype: int64\n",
      "running fold5\n",
      "hypertension    82\n",
      "normal          48\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    12\n",
      "normal           6\n",
      "dtype: int64\n",
      "running fold6\n",
      "hypertension    83\n",
      "normal          46\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    15\n",
      "normal           4\n",
      "dtype: int64\n",
      "running fold7\n",
      "hypertension    83\n",
      "normal          48\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    9\n",
      "normal          8\n",
      "dtype: int64\n",
      "running fold8\n",
      "hypertension    89\n",
      "normal          44\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    11\n",
      "normal           4\n",
      "dtype: int64\n",
      "running fold9\n",
      "hypertension    89\n",
      "normal          48\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    7\n",
      "normal          4\n",
      "dtype: int64\n",
      "average ACC for the LR for dbp is 0.5266666058590723 sd 0.11403780980591803\n",
      "average F1 for the LR for dbp is 0.5256222025964477 sd 0.12671438377014252\n",
      "average ACC for the GBC for dbp is 0.5795395475220037 sd 0.15333694443965326\n",
      "average F1 for the GBC for dbp is 0.5552817870323591 sd 0.17819569982009711\n"
     ]
    }
   ],
   "source": [
    "patient_ids = np.unique(df['patientid'])\n",
    "\n",
    "estimator_base = SVC(kernel=\"linear\")\n",
    "selector = RFE(estimator_base, 40, step=1)\n",
    "\n",
    "estimators_lr = []\n",
    "estimators_lr.append(('standardize', StandardScaler()))\n",
    "estimators_lr.append(('selector', selector))\n",
    "estimators_lr.append(('lr',  LogisticRegression(penalty='l2', C=0.1, random_state = 42, solver = 'lbfgs', multi_class = 'ovr', class_weight='balanced')))\n",
    "pipeline_lr = Pipeline(estimators_lr)\n",
    "\n",
    "estimators_gbc = []\n",
    "#estimators_gbc.append(('standardize', StandardScaler()))\n",
    "estimators_gbc.append(('selector', selector))\n",
    "estimators_gbc.append(('gbc',  GradientBoostingClassifier(learning_rate = 0.1, subsample = 0.5, random_state = 42)))\n",
    "pipeline_gbc = Pipeline(estimators_gbc)\n",
    "\n",
    "ACC_LR = []\n",
    "F1_LR = []\n",
    "\n",
    "ACC_GBC = []\n",
    "F1_GBC = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while len(patient_ids) > 1:\n",
    "    \n",
    "    i= i + 1\n",
    "    random.seed(42)\n",
    "    patient_test_ids = random.choices(patient_ids, k = 3)\n",
    "    patient_ids = [e for e in patient_ids if e not in patient_test_ids]\n",
    "    df_test = df.loc[df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    df_train = df[~df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    print(\"running fold\" + str(i))\n",
    "    \n",
    "    cols_dropped = ['patientid', 'sbp', 'dbp']\n",
    "    df_train = df_train.drop(columns = cols_dropped)\n",
    "    df_test = df_test.drop(columns = cols_dropped)\n",
    "    \n",
    "    #df_majority = df_train[df_train.BP_Category == 'hypertension']\n",
    "    #df_minority = df_train[(df_train.BP_Category == 'elivated') | (df_train.BP_Category == 'normal')]\n",
    "    \n",
    "    #df_minority_upsampled = resample(df_minority, \n",
    "    #                             replace=True,     # sample with replacement\n",
    "    #                             n_samples=150,    # to match majority class\n",
    "    #                             random_state=123) # reproducible results\n",
    "    #df_train = pd.concat([df_majority, df_minority_upsampled])\n",
    "    print(df_train['BP_Category'].value_counts())\n",
    " \n",
    "    \n",
    "    ##lr\n",
    "    pipeline_lr.fit(X = np.stack(df_train[\"representation\"]), y = df_train['BP_Category'].values)\n",
    "    predicted_labels = pipeline_lr.predict(np.stack(df_test[\"representation\"]))\n",
    "    print(pd.Series(predicted_labels).value_counts())\n",
    "    F1_LR.append(f1_score(df_test['BP_Category'], predicted_labels, average='weighted'))\n",
    "    ACC_LR.append(accuracy_score(df_test['BP_Category'], predicted_labels))\n",
    "    \n",
    "    ##gbc\n",
    "    \n",
    "    pipeline_gbc.fit(X = np.stack(df_train[\"representation\"]), y = df_train['BP_Category'].values)\n",
    "    predicted_labels = pipeline_gbc.predict(np.stack(df_test[\"representation\"]))\n",
    "    \n",
    "    F1_GBC.append(f1_score(df_test['BP_Category'], predicted_labels, average='weighted'))\n",
    "    ACC_GBC.append(accuracy_score(df_test['BP_Category'], predicted_labels))\n",
    "    \n",
    "\n",
    "print(\"average ACC for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(ACC_LR)))+ \" sd \" + str(np.std(np.array(ACC_LR)))) \n",
    "print(\"average F1 for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(F1_LR)))+ \" sd \" + str(np.std(np.array(F1_LR))))\n",
    "\n",
    "\n",
    "print(\"average ACC for the GBC for \" + predicted_variable + \" is \" + str(np.mean(np.array(ACC_GBC)))+ \" sd \" + str(np.std(np.array(ACC_GBC)))) \n",
    "print(\"average F1 for the GBC for \" + predicted_variable + \" is \" + str(np.mean(np.array(F1_GBC)))+ \" sd \" + str(np.std(np.array(F1_GBC))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}