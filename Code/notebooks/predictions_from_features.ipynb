{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import biosppy\n",
    "import operator\n",
    "import re\n",
    "#import import_ipynb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_variable = 'DBP' # \n",
    "correlation_threshold = 0.95\n",
    "compute_pvalue = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_correlation(df, labels, threshold = 0.95, plotcorr = False):\n",
    "    corr = df.loc[:, ~df.columns.isin(labels)].corr()\n",
    "    if plotcorr: \n",
    "        f, ax = plt.subplots(figsize=(15, 15))\n",
    "        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "        sns.heatmap(corr, cmap = cmap,\n",
    "                xticklabels=corr.columns.values,\n",
    "                yticklabels=corr.columns.values)\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr.abs().where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    len(to_drop)\n",
    "    # Drop features \n",
    "    print(\"New Dataframe Shape\" + str(df.shape))\n",
    "    return(df.drop(columns = to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../intermediate_data/bp_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 45)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 45)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.loc[(df['SBP'] == 0)|(df['DBP'] == 0)].index, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dataframe Shape(149, 45)\n",
      "(149, 30)\n"
     ]
    }
   ],
   "source": [
    "df = drop_correlation(df, ['SBP', 'DBP'], correlation_threshold, plotcorr = False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=(27,)))\n",
    "    model.add(Dense(50, input_dim=27, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(20, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(5, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fold1\n",
      "running fold2\n",
      "running fold3\n",
      "running fold4\n",
      "running fold5\n",
      "running fold6\n",
      "running fold7\n",
      "running fold8\n",
      "running fold9\n",
      "average RMSE for the NN for DBP is 12.136126654342045 sd 4.594369297274952\n",
      "average R2 for the NN for DBP is -2.473892881856523 sd 1.9373829172551815\n",
      "average MAPE for the NN for DBP is 13.438211127030472 sd 5.1722108442806904\n",
      "average RMSE for the LR for DBP is 8.614078165201596 sd 2.830945459727786\n",
      "average R2 for the LR for DBP is -0.7720423104814619 sd 1.3651175070524055\n",
      "average MAPE for the LR for DBP is 10.502411715456965 sd 4.6144672454089415\n",
      "average RMSE for the GBM for DBP is 8.78383523162713 sd 3.114621797934496\n",
      "average R2 for the GBM for DBP is -0.9348632630076601 sd 1.7094361959200173\n",
      "average MAPE for the GBM for DBP is 10.724531859277501 sd 5.136914611099583\n"
     ]
    }
   ],
   "source": [
    "#num_features = df_train.loc[:, df_train.columns != predicted_variable].shape[1]\n",
    "patient_ids = np.unique(df['patientid'])\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "estimators_lr = []\n",
    "estimators_lr.append(('standardize', StandardScaler()))\n",
    "estimators_lr.append(('lr',  ElasticNet(alpha=1, l1_ratio=0.5, random_state = 42)))\n",
    "pipeline_lr = Pipeline(estimators_lr)\n",
    "\n",
    "estimators_gbm = []\n",
    "estimators_gbm.append(('standardize', StandardScaler()))\n",
    "estimators_gbm.append(('gbm',  GradientBoostingRegressor(learning_rate=0.01, n_estimators=100, random_state = 42)))\n",
    "pipeline_gbm = Pipeline(estimators_gbm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RMSE_NN = []\n",
    "R2_NN = []\n",
    "MAPE_NN = []\n",
    "\n",
    "RMSE_LR = []\n",
    "R2_LR = []\n",
    "MAPE_LR = []\n",
    "\n",
    "RMSE_GBM = []\n",
    "R2_GBM = []\n",
    "MAPE_GBM = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while len(patient_ids) > 1:\n",
    "    \n",
    "    i= i + 1\n",
    "    random.seed(42)\n",
    "    patient_test_ids = random.choices(patient_ids, k = 3)\n",
    "    patient_ids = [e for e in patient_ids if e not in patient_test_ids]\n",
    "    df_test = df.loc[df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    df_train = df[~df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    print(\"running fold\" + str(i))\n",
    "    \n",
    "    cols_dropped = ['patientid']\n",
    "\n",
    "    if predicted_variable == 'SBP':\n",
    "        cols_dropped.append('DBP')\n",
    "    elif predicted_variable == 'DBP':\n",
    "        cols_dropped.append('SBP')\n",
    "    df_train = df_train.drop(columns = cols_dropped)\n",
    "    df_test = df_test.drop(columns = cols_dropped)\n",
    "    \n",
    "    ##nn\n",
    "    pipeline.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, y = df_train[predicted_variable].values)\n",
    "    predicted_labels = pipeline.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "    \n",
    "    RMSE_NN.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "    R2_NN.append(r2_score(df_test[predicted_variable], predicted_labels))\n",
    "    MAPE_NN.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    ##lr\n",
    "    pipeline_lr.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, y = df_train[predicted_variable].values)\n",
    "    predicted_labels = pipeline_lr.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "    \n",
    "    RMSE_LR.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "    R2_LR.append(r2_score(df_test[predicted_variable], predicted_labels))\n",
    "    MAPE_LR.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    #gbm \n",
    "    \n",
    "    pipeline_gbm.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, y = df_train[predicted_variable].values)\n",
    "    predicted_labels = pipeline_gbm.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "    \n",
    "    RMSE_GBM.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "    R2_GBM.append(r2_score(df_test[predicted_variable], predicted_labels))\n",
    "    MAPE_GBM.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate model with standardized dataset\n",
    "    \n",
    "print(\"average RMSE for the NN for \" + predicted_variable + \" is \" + str(np.mean(np.array(RMSE_NN)))+ \" sd \" + str(np.std(np.array(RMSE_NN)))) \n",
    "print(\"average R2 for the NN for \" + predicted_variable + \" is \" + str(np.mean(np.array(R2_NN)))+ \" sd \" + str(np.std(np.array(R2_NN))))\n",
    "print(\"average MAPE for the NN for \" + predicted_variable + \" is \" + str(np.mean(np.array(MAPE_NN)))+ \" sd \" + str(np.std(np.array(MAPE_NN))))\n",
    "\n",
    "print(\"average RMSE for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(RMSE_LR)))+ \" sd \" + str(np.std(np.array(RMSE_LR)))) \n",
    "print(\"average R2 for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(R2_LR)))+ \" sd \" + str(np.std(np.array(R2_LR))))\n",
    "print(\"average MAPE for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(MAPE_LR)))+ \" sd \" + str(np.std(np.array(MAPE_LR))))\n",
    "\n",
    "print(\"average RMSE for the GBM for \" + predicted_variable + \" is \" + str(np.mean(np.array(RMSE_GBM)))+ \" sd \" + str(np.std(np.array(RMSE_GBM)))) \n",
    "print(\"average R2 for the GBM for \" + predicted_variable + \" is \" + str(np.mean(np.array(R2_GBM)))+ \" sd \" + str(np.std(np.array(R2_GBM))))\n",
    "print(\"average MAPE for the GBM for \" + predicted_variable + \" is \" + str(np.mean(np.array(MAPE_GBM)))+ \" sd \" + str(np.std(np.array(MAPE_GBM))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification\n",
    "\n",
    "df['BP_Category'] = 'normal'\n",
    "#df.loc[(df['SBP'] > 120) & (df['SBP'] < 130) & (df['DBP'] < 80), 'BP_Category'] = 'elivated'\n",
    "df.loc[(df['SBP'] > 130) | (df['DBP'] > 80), 'BP_Category'] = 'hypertension'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hypertension    95\n",
       "normal          54\n",
       "Name: BP_Category, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BP_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fold1\n",
      "normal          150\n",
      "hypertension     84\n",
      "Name: BP_Category, dtype: int64\n",
      "normal          12\n",
      "hypertension     6\n",
      "dtype: int64\n",
      "running fold2\n",
      "normal          150\n",
      "hypertension     87\n",
      "Name: BP_Category, dtype: int64\n",
      "normal          14\n",
      "hypertension     2\n",
      "dtype: int64\n",
      "running fold3\n",
      "normal          150\n",
      "hypertension     82\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    13\n",
      "normal           4\n",
      "dtype: int64\n",
      "running fold4\n",
      "normal          150\n",
      "hypertension     81\n",
      "Name: BP_Category, dtype: int64\n",
      "normal          10\n",
      "hypertension     8\n",
      "dtype: int64\n",
      "running fold5\n",
      "normal          150\n",
      "hypertension     82\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    11\n",
      "normal           7\n",
      "dtype: int64\n",
      "running fold6\n",
      "normal          150\n",
      "hypertension     83\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    15\n",
      "normal           4\n",
      "dtype: int64\n",
      "running fold7\n",
      "normal          150\n",
      "hypertension     83\n",
      "Name: BP_Category, dtype: int64\n",
      "normal          13\n",
      "hypertension     4\n",
      "dtype: int64\n",
      "running fold8\n",
      "normal          150\n",
      "hypertension     89\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    11\n",
      "normal           4\n",
      "dtype: int64\n",
      "running fold9\n",
      "normal          150\n",
      "hypertension     89\n",
      "Name: BP_Category, dtype: int64\n",
      "hypertension    7\n",
      "normal          3\n",
      "dtype: int64\n",
      "average ACC for the LR for DBP is 0.659201926384589 sd 0.16350886112392152\n",
      "average F1 for the LR for DBP is 0.6441849013400441 sd 0.18450331560787356\n",
      "average ACC for the GBC for DBP is 0.575839448839965 sd 0.20965064072824113\n",
      "average F1 for the GBC for DBP is 0.562886825872722 sd 0.2170168188659549\n"
     ]
    }
   ],
   "source": [
    "patient_ids = np.unique(df['patientid'])\n",
    "\n",
    "estimators_lr = []\n",
    "estimators_lr.append(('standardize', StandardScaler()))\n",
    "estimators_lr.append(('lr',  LogisticRegression(penalty='l2', C=0.2, random_state = 42, solver = 'lbfgs', multi_class = 'ovr')))\n",
    "pipeline_lr = Pipeline(estimators_lr)\n",
    "\n",
    "estimators_gbc = []\n",
    "estimators_gbc.append(('standardize', StandardScaler()))\n",
    "estimators_gbc.append(('gbc',  GradientBoostingClassifier(learning_rate = 0.1, subsample = 0.5, random_state = 42)))\n",
    "pipeline_gbc = Pipeline(estimators_gbc)\n",
    "\n",
    "ACC_LR = []\n",
    "F1_LR = []\n",
    "\n",
    "ACC_GBC = []\n",
    "F1_GBC = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while len(patient_ids) > 1:\n",
    "    \n",
    "    i= i + 1\n",
    "    random.seed(42)\n",
    "    patient_test_ids = random.choices(patient_ids, k = 3)\n",
    "    patient_ids = [e for e in patient_ids if e not in patient_test_ids]\n",
    "    df_test = df.loc[df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    df_train = df[~df['patientid'].isin(patient_test_ids)].dropna()\n",
    "    print(\"running fold\" + str(i))\n",
    "    \n",
    "    cols_dropped = ['patientid', 'SBP', 'DBP']\n",
    "    df_train = df_train.drop(columns = cols_dropped)\n",
    "    df_test = df_test.drop(columns = cols_dropped)\n",
    "    \n",
    "    df_majority = df_train[df_train.BP_Category == 'hypertension']\n",
    "    df_minority = df_train[(df_train.BP_Category == 'elivated') | (df_train.BP_Category == 'normal')]\n",
    "    \n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=150,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "    df_train = pd.concat([df_majority, df_minority_upsampled])\n",
    "    print(df_train['BP_Category'].value_counts())\n",
    " \n",
    "    \n",
    "    ##lr\n",
    "    pipeline_lr.fit(X = df_train.loc[:, df_train.columns != 'BP_Category'].values, y = df_train['BP_Category'].values)\n",
    "    predicted_labels = pipeline_lr.predict(df_test.loc[:, df_test.columns != 'BP_Category'].values)\n",
    "    print(pd.Series(predicted_labels).value_counts())\n",
    "    F1_LR.append(f1_score(df_test['BP_Category'], predicted_labels, average='weighted'))\n",
    "    ACC_LR.append(accuracy_score(df_test['BP_Category'], predicted_labels))\n",
    "    \n",
    "    ##gbc\n",
    "    \n",
    "    pipeline_gbc.fit(X = df_train.loc[:, df_train.columns != 'BP_Category'].values, y = df_train['BP_Category'].values)\n",
    "    predicted_labels = pipeline_gbc.predict(df_test.loc[:, df_test.columns != 'BP_Category'].values)\n",
    "    \n",
    "    F1_GBC.append(f1_score(df_test['BP_Category'], predicted_labels, average='weighted'))\n",
    "    ACC_GBC.append(accuracy_score(df_test['BP_Category'], predicted_labels))\n",
    "    \n",
    "\n",
    "print(\"average ACC for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(ACC_LR)))+ \" sd \" + str(np.std(np.array(ACC_LR)))) \n",
    "print(\"average F1 for the LR for \" + predicted_variable + \" is \" + str(np.mean(np.array(F1_LR)))+ \" sd \" + str(np.std(np.array(F1_LR))))\n",
    "\n",
    "\n",
    "print(\"average ACC for the GBC for \" + predicted_variable + \" is \" + str(np.mean(np.array(ACC_GBC)))+ \" sd \" + str(np.std(np.array(ACC_GBC)))) \n",
    "print(\"average F1 for the GBC for \" + predicted_variable + \" is \" + str(np.mean(np.array(F1_GBC)))+ \" sd \" + str(np.std(np.array(F1_GBC))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
